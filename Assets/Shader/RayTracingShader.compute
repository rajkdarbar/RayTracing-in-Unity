// Each #kernel tells which function to compile; you can have many kernels.

/*

Why You See Sphere Reflections: 
The reflections of other spheres you're seeing are not from the direct color contribution of sphere hits (since they return black), 
but rather from the cumulative effect of the ray's journey, reflecting off multiple spheres before finally hitting the skybox. Each reflection alters the ray's path, 
and when it eventually hits the skybox, the color sampled is based on the final direction of the ray, which has been influenced by all the previous reflections.

Direct vs. Indirect Contribution: 
The reflections of spheres are indirect contributions. The spheres do not directly add color to the ray at the point of hit, 
but they influence the ray's path, which eventually determines the color sampled from the skybox. 

In essence, the color of each pixel in your rendered image is a result of the entire path a ray takes through the scene, 
including all reflections and their cumulative influence on the ray's direction, leading to the final color contribution from the skybox.

*/

#pragma kernel CSMain

RWTexture2D<float4> Result; // This is a writable texture to store the final rendered image.

float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;

float4 _DirectionalLight;

float2 _PixelOffset;

Texture2D<float4> _SkyboxTexture;
SamplerState sampler_SkyboxTexture;
static const float PI = 3.14159265f;

struct Sphere
{
    float3 position;
    float radius;
    float3 albedo; // Diffuse property
    float3 specular; // Reflective property
};

StructuredBuffer<Sphere> _Spheres;

struct Ray
{
    float3 origin;
    float3 direction;  
    float3 energy;  
};

struct RayHit
{
    float3 position;
    float distance;
    float3 normal;
    float3 albedo;
    float3 specular;
};

Ray CreateRay(float3 origin, float3 direction)
{
    Ray ray;
    ray.origin = origin;
    ray.direction = direction;
    ray.energy = float3(1.0f, 1.0f, 1.0f);
    return ray;
}

Ray CreateCameraRay(float2 uv)
{
    // Transform the camera origin to world space
    float3 origin = mul(_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    
    // Converting a 2D point on the screen (uv) back into 3D space
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;

    // Transform the direction from camera to world space and normalize
    direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);

    return CreateRay(origin, direction);
}

RayHit CreateRayHit()
{
    RayHit hit;
    hit.position = float3(0.0f, 0.0f, 0.0f);
    hit.distance = 1.#INF;
    hit.normal = float3(0.0f, 0.0f, 0.0f);
    hit.albedo = float3(0.0f, 0.0f, 0.0f);
    hit.specular = float3(0.0f, 0.0f, 0.0f);
    return hit;
}


void IntersectGroundPlane(Ray ray, inout RayHit bestHit)
{
    // Calculate distance along the ray where the ground plane is intersected
    float t = -ray.origin.y / ray.direction.y; // This ground plane is aligned with XZ plane
    if (t > 0 && t < bestHit.distance)
    {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.normal = float3(0.0f, 1.0f, 0.0f);
        bestHit.albedo = 0.8f;
        bestHit.specular = 0.2f;
    }
}

void IntersectSphere(Ray ray, inout RayHit bestHit, uint sphereIndex)
{
    // Calculate distance along the ray where the sphere is intersected
    Sphere sphere = _Spheres[sphereIndex];
    float3 d = ray.origin - sphere.position;
    float p1 = -dot(ray.direction, d);
    float p2sqr = p1 * p1 - dot(d, d) + sphere.radius * sphere.radius;
    if (p2sqr < 0)
        return;
    float p2 = sqrt(p2sqr);
    float t = p1 - p2 > 0 ? p1 - p2 : p1 + p2;
    if (t > 0 && t < bestHit.distance)
    {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.normal = normalize(bestHit.position - sphere.position);
        bestHit.albedo = sphere.albedo;
        bestHit.specular = sphere.specular;
    }
}

RayHit Trace(Ray ray)
{
    RayHit bestHit = CreateRayHit();

    // Trace ground plane
    IntersectGroundPlane(ray, bestHit);

    // Trace spheres
    uint numSpheres, stride;
    _Spheres.GetDimensions(numSpheres, stride);

    for (uint i = 0; i < numSpheres; i++)
        IntersectSphere(ray, bestHit, i);

    return bestHit;
}

float3 Shade(inout Ray ray, RayHit hit)
{
    if (hit.distance < 1.#INF)
    { 
        // Reflect the ray and multiply energy with specular component
        ray.origin = hit.position + hit.normal * 0.001f;
        ray.direction = reflect(ray.direction, hit.normal);
        ray.energy *= hit.specular; // returns a vector3

        // Shadow test ray
        bool shadow = false;
        Ray shadowRay = CreateRay(hit.position + hit.normal * 0.001f, -1 * _DirectionalLight.xyz);
        RayHit shadowHit = Trace(shadowRay);
        if (shadowHit.distance != 1.#INF)
        {
            return float3(0.0f, 0.0f, 0.0f);
        }

        // Return a diffuse-shaded color        
        return saturate(dot(hit.normal, _DirectionalLight.xyz) * -1) * _DirectionalLight.w * hit.albedo; // It returns a Vector3
        //return saturate(dot(hit.normal, -1 * _DirectionalLight.xyz)) * _DirectionalLight.w * hit.albedo;
    }
    else
    {
        // Erase the ray's energy - the sky doesn't reflect anything
        ray.energy = 0.0f;
        // Sample the skybox and write it
        float theta = acos(ray.direction.y) / -PI; // Measure angle between ray direction and y-axis
        float phi = atan2(ray.direction.x, -ray.direction.z) / -PI * 0.5f; // Measuring the angle from the positive x-axis to the projected vector direction on xz plane 
        
        float skyboxIntensityFactor = 1.36f; // Example value, adjust as needed
        float3 skyboxColor = _SkyboxTexture.SampleLevel(sampler_SkyboxTexture, float2(phi, theta), 0).xyz; // Get the color from the texture based on the phi and theta coordinates. The 0 indicates no mipmaps.
        return skyboxColor * skyboxIntensityFactor;
    }
}

[numthreads(8,8,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
    // Get the dimensions of the RenderTexture
    uint width, height;
    Result.GetDimensions(width, height);

    // Transform pixel to [-1,1] range for DirectX used by Unity
    float2 uv = float2((id.xy + _PixelOffset) / float2(width, height) * 2.0f - 1.0f);

    // Get a ray for the UVs
    Ray ray = CreateCameraRay(uv); 

    // Trace and shade the ray
    float3 result = float3(0, 0, 0);
    for (int i = 0; i < 10; i++)
    {
        RayHit hit = Trace(ray);        
        result += ray.energy * Shade(ray, hit); // Here, we are considering energy of the incident ray

        if (!any(ray.energy))
            break;
    }

    Result[id.xy] = float4(result, 1); 
}